% Generated by Paperpile. Check out https://paperpile.com for more information.
% BibTeX export options can be customized via Settings -> BibTeX.

@ARTICLE{Fowler2017,
  title     = "Frictionless Data: Making Research Data Quality Visible",
  author    = "Fowler, Dan and Barratt, Jo and Walsh, Paul",
  journal   = "IJDC",
  publisher = "dcc-drupal.edina.ac.uk",
  volume    =  12,
  number    =  2,
  pages     = "274--285",
  year      =  2017
}


@ARTICLE{Stodden2018,
  title    = "An empirical analysis of journal policy effectiveness for
              computational reproducibility",
  author   = "Stodden, Victoria and Seiler, Jennifer and Ma, Zhaokun",
  abstract = "A key component of scientific communication is sufficient
              information for other researchers in the field to reproduce
              published findings. For computational and data-enabled research,
              this has often been interpreted to mean making available the raw
              data from which results were generated, the computer code that
              generated the findings, and any additional information needed
              such as workflows and input parameters. Many journals are
              revising author guidelines to include data and code availability.
              This work evaluates the effectiveness of journal policy that
              requires the data and code necessary for reproducibility be made
              available postpublication by the authors upon request. We assess
              the effectiveness of such a policy by (i) requesting data and
              code from authors and (ii) attempting replication of the
              published findings. We chose a random sample of 204 scientific
              papers published in the journal Science after the implementation
              of their policy in February 2011. We found that we were able to
              obtain artifacts from 44\% of our sample and were able to
              reproduce the findings for 26\%. We find this policy-author
              remission of data and code postpublication upon request-an
              improvement over no policy, but currently insufficient for
              reproducibility.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  115,
  number   =  11,
  pages    = "2584--2589",
  month    =  mar,
  year     =  2018,
  keywords = "code access; data access; open science; reproducibility policy;
              reproducible research",
  language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Zagalsky2015,
  title     = "The Emergence of {GitHub} as a Collaborative Platform for
               Education",
  booktitle = "Proceedings of the 18th {ACM} Conference on Computer Supported
               Cooperative Work \& Social Computing",
  author    = "Zagalsky, Alexey and Feliciano, Joseph and Storey, Margaret-Anne
               and Zhao, Yiyun and Wang, Weiliang",
  abstract  = "… experience for students and teachers. Only a few years after
               GitHub's 2007 release, well-known computer science educator Greg
               Wilson suggested4 that GitHub could be used for learning
               materials despite some limitations …",
  publisher = "Association for Computing Machinery",
  pages     = "1906--1917",
  series    = "CSCW '15",
  month     =  feb,
  year      =  2015,
  address   = "New York, NY, USA",
  keywords  = "github, learning, education, distributed version control, cscl,
               cscw, social media, qualitative methodology",
  location  = "Vancouver, BC, Canada"
}

@ARTICLE{Ram2013,
  title    = "Git can facilitate greater reproducibility and increased
              transparency in science",
  author   = "Ram, Karthik",
  abstract = "BACKGROUND: Reproducibility is the hallmark of good science.
              Maintaining a high degree of transparency in scientific reporting
              is essential not just for gaining trust and credibility within
              the scientific community but also for facilitating the
              development of new ideas. Sharing data and computer code
              associated with publications is becoming increasingly common,
              motivated partly in response to data deposition requirements from
              journals and mandates from funders. Despite this increase in
              transparency, it is still difficult to reproduce or build upon
              the findings of most scientific publications without access to a
              more complete workflow. FINDINGS: Version control systems (VCS),
              which have long been used to maintain code repositories in the
              software industry, are now finding new applications in science.
              One such open source VCS, Git, provides a lightweight yet robust
              framework that is ideal for managing the full suite of research
              outputs such as datasets, statistical code, figures, lab notes,
              and manuscripts. For individual researchers, Git provides a
              powerful way to track and compare versions, retrace errors,
              explore new approaches in a structured manner, while maintaining
              a full audit trail. For larger collaborative efforts, Git and Git
              hosting services make it possible for everyone to work
              asynchronously and merge their contributions at any time, all the
              while maintaining a complete authorship trail. In this paper I
              provide an overview of Git along with use-cases that highlight
              how this tool can be leveraged to make science more reproducible
              and transparent, foster new collaborations, and support novel
              uses.",
  journal  = "Source Code Biol. Med.",
  volume   =  8,
  number   =  1,
  pages    = "7",
  month    =  feb,
  year     =  2013,
  language = "en"
}

@ARTICLE{Pugachev2019,
  title     = "What Are`` The Carpentries'' and What Are They Doing in the
               Library?",
  author    = "Pugachev, Sarah",
  journal   = "portal: Libraries and the Academy",
  publisher = "Johns Hopkins University Press",
  volume    =  19,
  number    =  2,
  pages     = "209--214",
  year      =  2019
}

@BOOK{Nielsen2020,
  title     = "Reinventing Discovery: The New Era of Networked Science",
  author    = "Nielsen, Michael",
  abstract  = "How the internet and powerful online tools are democratizing and
               accelerating scientific discoveryReinventing Discovery argues
               that we are living at the dawn of the most dramatic change in
               science in more than three hundred years. This change is being
               driven by powerful cognitive tools, enabled by the internet,
               which are greatly accelerating scientific discovery. There are
               many books about how the internet is changing business, the
               workplace, or government. But this is the first book about
               something much more fundamental: how the internet is
               transforming our collective intelligence and our understanding
               of the world. From the collaborative mathematicians of the
               Polymath Project to the amateur astronomers of Galaxy Zoo,
               Reinventing Discovery tells the exciting story of the
               unprecedented new era in networked science. It will interest
               anyone who wants to learn about how the online world is
               revolutionizing scientific discovery---and why the revolution is
               just beginning.",
  publisher = "Princeton University Press",
  month     =  apr,
  year      =  2020,
  language  = "en"
}

@ARTICLE{Collberg2014,
  title   = "Measuring reproducibility in computer systems research",
  author  = "Collberg, Christian and Proebsting, Todd and Moraila, Gina and
             Shankaran, Akash and Shi, Zuoming and Warren, Alex M",
  journal = "Department of Computer Science, University of Arizona, Tech. Rep",
  volume  =  37,
  year    =  2014
}

@ARTICLE{Barnes2010,
  title    = "Publish your computer code: it is good enough",
  author   = "Barnes, Nick",
  journal  = "Nature",
  volume   =  467,
  number   =  7317,
  pages    = "753",
  month    =  oct,
  year     =  2010,
  language = "en"
}

@ARTICLE{Peng2011,
  title    = "Reproducible research in computational science",
  author   = "Peng, Roger D",
  abstract = "Computational science has led to exciting new developments, but
              the nature of the work has exposed limitations in our ability to
              evaluate published findings. Reproducibility has the potential to
              serve as a minimum standard for judging scientific claims when
              full independent replication of a study is not possible.",
  journal  = "Science",
  volume   =  334,
  number   =  6060,
  pages    = "1226--1227",
  month    =  dec,
  year     =  2011,
  language = "en"
}

@ARTICLE{Roche2015,
  title    = "Public Data Archiving in Ecology and Evolution: How Well Are We
              Doing?",
  author   = "Roche, Dominique G and Kruuk, Loeske E B and Lanfear, Robert and
              Binning, Sandra A",
  abstract = "Policies that mandate public data archiving (PDA) successfully
              increase accessibility to data underlying scientific
              publications. However, is the data quality sufficient to allow
              reuse and reanalysis? We surveyed 100 datasets associated with
              nonmolecular studies in journals that commonly publish ecological
              and evolutionary research and have a strong PDA policy. Out of
              these datasets, 56\% were incomplete, and 64\% were archived in a
              way that partially or entirely prevented reuse. We suggest that
              cultural shifts facilitating clearer benefits to authors are
              necessary to achieve high-quality PDA and highlight key
              guidelines to help authors increase their data's reuse potential
              and compliance with journal data policies.",
  journal  = "PLoS Biol.",
  volume   =  13,
  number   =  11,
  pages    = "e1002295",
  month    =  nov,
  year     =  2015,
  language = "en"
}


@MISC{Jupyter2018,
  title   = "Binder 2.0 - Reproducible, interactive, sharable environments for
             science at scale",
  author  = "Jupyter, Project and {Project Jupyter} and Bussonnier, Matthias
             and Forde, Jessica and Freeman, Jeremy and Granger, Brian and
             Head, Tim and Holdgraf, Chris and Kelley, Kyle and Nalvarte,
             Gladys and Osheroff, Andrew and Pacer, M and Panda, Yuvi and
             Perez, Fernando and Ragan-Kelley, Benjamin and Willing, Carol",
  journal = "Proceedings of the 17th Python in Science Conference",
  year    =  2018
}

@ARTICLE{Smith2018,
  title     = "Journal of Open Source Software ({JOSS)}: design and first-year
               review",
  author    = "Smith, Arfon M and Niemeyer, Kyle E and Katz, Daniel S and
               Barba, Lorena A and Githinji, George and Gymrek, Melissa and
               Huff, Kathryn D and Madan, Christopher R and Mayes, Abigail
               Cabunoc and Moerman, Kevin M and Prins, Pjotr and Ram, Karthik
               and Rokem, Ariel and Teal, Tracy K and Guimera, Roman Valls and
               Vanderplas, Jacob T",
  abstract  = "This article describes the motivation, design, and progress of
               the Journal of Open Source Software (JOSS). JOSS is a free and
               open-access journal that publishes articles describing research
               software. It has the dual goals of improving the quality of the
               software submitted and providing a mechanism for research
               software developers to receive credit. While designed to work
               within the current merit system of science, JOSS addresses the
               dearth of rewards for key contributions to science made in the
               form of software. JOSS publishes articles that encapsulate
               scholarship contained in the software itself, and its rigorous
               peer review targets the software components: functionality,
               documentation, tests, continuous integration, and the license. A
               JOSS article contains an abstract describing the purpose and
               functionality of the software, references, and a link to the
               software archive. The article is the entry point of a JOSS
               submission, which encompasses the full set of software
               artifacts. Submission and review proceed in the open, on GitHub.
               Editors, reviewers, and authors work collaboratively and openly.
               Unlike other journals, JOSS does not reject articles requiring
               major revision; while not yet accepted, articles remain visible
               and under review until the authors make adequate changes (or
               withdraw, if unable to meet requirements). Once an article is
               accepted, JOSS gives it a digital object identifier (DOI),
               deposits its metadata in Crossref, and the article can begin
               collecting citations on indexers like Google Scholar and other
               services. Authors retain copyright of their JOSS article,
               releasing it under a Creative Commons Attribution 4.0
               International License. In its first year, starting in May 2016,
               JOSS published 111 articles, with more than 40 additional
               articles under review. JOSS is a sponsored project of the
               nonprofit organization NumFOCUS and is an affiliate of the Open
               Source Initiative (OSI).",
  journal   = "PeerJ Comput. Sci.",
  publisher = "PeerJ Inc.",
  volume    =  4,
  pages     = "e147",
  month     =  feb,
  year      =  2018,
  keywords  = "Research software; Code review; Computational research; Software
               citation; Open-source software; Scholarly publishing",
  language  = "en"
}

@ARTICLE{Boettiger2015,
  title     = "An introduction to Docker for reproducible research",
  author    = "Boettiger, Carl",
  journal   = "Oper. Syst. Rev.",
  publisher = "Association for Computing Machinery",
  volume    =  49,
  number    =  1,
  pages     = "71--79",
  month     =  jan,
  year      =  2015,
  address   = "New York, NY, USA"
}

@ARTICLE{Donoho2017,
  title     = "50 Years of Data Science",
  author    = "Donoho, David",
  journal   = "Journal of computational and graphical statistics: a joint
               publication of American Statistical Association, Institute of
               Mathematical Statistics, Interface Foundation of North America",
  publisher = "Taylor \& Francis",
  volume    =  26,
  number    =  4,
  pages     = "745--766",
  month     =  oct,
  year      =  2017
}


@article{McKiernan2016, title={How open science helps researchers succeed}, volume={5}, url={http://dx.doi.org/10.7554/eLife.16800}, DOI={10.7554/elife.16800}, abstractNote={<jats:p>Open access, open data, open source and other open scholarship practices are growing in popularity and necessity. However, widespread adoption of these practices has not yet been achieved. One reason is that researchers are uncertain about how sharing their work will affect their careers. We review literature demonstrating that open research is associated with increases in citations, media attention, potential collaborators, job opportunities and funding opportunities. These findings are evidence that open research practices bring significant benefits to researchers relative to more traditional closed practices.</jats:p>}, journal={eLife}, publisher={eLife Sciences Publications, Ltd}, author={McKiernan, Erin C and Bourne, Philip E and Brown, C Titus and Buck, Stuart and Kenall, Amye and Lin, Jennifer and McDougall, Damon and Nosek, Brian A and Ram, Karthik and Soderberg, Courtney K and et al.}, year={2016}, month={Jul} }

@ARTICLE{Colavizza2020,
  title    = "The citation advantage of linking publications to research data",
  author   = "Colavizza, Giovanni and Hrynaszkiewicz, Iain and Staden, Isla and
              Whitaker, Kirstie and McGillivray, Barbara",
  abstract = "Efforts to make research results open and reproducible are
              increasingly reflected by journal policies encouraging or
              mandating authors to provide data availability statements. As a
              consequence of this, there has been a strong uptake of data
              availability statements in recent literature. Nevertheless, it is
              still unclear what proportion of these statements actually
              contain well-formed links to data, for example via a URL or
              permanent identifier, and if there is an added value in providing
              such links. We consider 531, 889 journal articles published by
              PLOS and BMC, develop an automatic system for labelling their
              data availability statements according to four categories based
              on their content and the type of data availability they display,
              and finally analyze the citation advantage of different statement
              categories via regression. We find that, following mandated
              publisher policies, data availability statements become very
              common. In 2018 93.7\% of 21,793 PLOS articles and 88.2\% of
              31,956 BMC articles had data availability statements. Data
              availability statements containing a link to data in a
              repository-rather than being available on request or included as
              supporting information files-are a fraction of the total. In 2017
              and 2018, 20.8\% of PLOS publications and 12.2\% of BMC
              publications provided DAS containing a link to data in a
              repository. We also find an association between articles that
              include statements that link to data in a repository and up to
              25.36\% ($\pm$ 1.07\%) higher citation impact on average, using a
              citation prediction model. We discuss the potential implications
              of these results for authors (researchers) and journal publishers
              who make the effort of sharing their data in repositories. All
              our data and code are made available in order to reproduce and
              extend our results.",
  journal  = "PLoS One",
  volume   =  15,
  number   =  4,
  pages    = "e0230416",
  month    =  apr,
  year     =  2020,
  language = "en"
}

@ARTICLE{Wilkinson2016,
  title    = "The {FAIR} Guiding Principles for scientific data management and
              stewardship",
  author   = "Wilkinson, Mark D and Dumontier, Michel and Aalbersberg, I
              Jsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak,
              Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva
              Santos, Luiz Bonino and Bourne, Philip E and Bouwman, Jildau and
              Brookes, Anthony J and Clark, Tim and Crosas, Merc{\`e} and
              Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo,
              Chris T and Finkers, Richard and Gonzalez-Beltran, Alejandra and
              Gray, Alasdair J G and Groth, Paul and Goble, Carole and Grethe,
              Jeffrey S and Heringa, Jaap and 't Hoen, Peter A C and Hooft, Rob
              and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott
              J and Martone, Maryann E and Mons, Albert and Packer, Abel L and
              Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van
              Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and
              Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz,
              Morris A and Thompson, Mark and van der Lei, Johan and van
              Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and
              Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and
              Mons, Barend",
  abstract = "There is an urgent need to improve the infrastructure supporting
              the reuse of scholarly data. A diverse set of
              stakeholders-representing academia, industry, funding agencies,
              and scholarly publishers-have come together to design and jointly
              endorse a concise and measureable set of principles that we refer
              to as the FAIR Data Principles. The intent is that these may act
              as a guideline for those wishing to enhance the reusability of
              their data holdings. Distinct from peer initiatives that focus on
              the human scholar, the FAIR Principles put specific emphasis on
              enhancing the ability of machines to automatically find and use
              the data, in addition to supporting its reuse by individuals.
              This Comment is the first formal publication of the FAIR
              Principles, and includes the rationale behind them, and some
              exemplar implementations in the community.",
  journal  = "Sci Data",
  volume   =  3,
  pages    = "160018",
  month    =  mar,
  year     =  2016,
  language = "en"
}

@MISC{Arslan2019,
  title   = "How to Automatically Document Data With the codebook Package to
             Facilitate Data Reuse",
  author  = "Arslan, Ruben C",
  journal = "Advances in Methods and Practices in Psychological Science",
  volume  =  2,
  number  =  2,
  pages   = "169--187",
  year    =  2019
}

@ARTICLE{Wilson2014,
  title    = "Software Carpentry: lessons learned",
  author   = "Wilson, Greg",
  abstract = "Since its start in 1998, Software Carpentry has evolved from a
              week-long training course at the US national laboratories into a
              worldwide volunteer effort to improve researchers' computing
              skills. This paper explains what we have learned along the way,
              the challenges we now face, and our plans for the future.",
  journal  = "F1000Res.",
  volume   =  3,
  pages    = "62",
  month    =  feb,
  year     =  2014,
  keywords = "Education; Scientific Computing; Software Carpentry; Training",
  language = "en"
}

@misc{ccby-short,
 title = {CCBY Short Guide},
 howpublished = {https://creativecommons.org/licenses/by/4.0/},
 note = {Accessed: 2019-05-09}
}

@misc{ccby-long,
 title = {CCBY Full License},
 howpublished = {https://creativecommons.org/licenses/by/4.0/legalcode},
 note = {Accessed: 2019-05-09}
}

@TECHREPORT{Broman2017,
  title       = "Data organization in spreadsheets",
  author      = "Broman, Karl W and Woo, Kara H",
  publisher   = "PeerJ Inc.",
  number      = "e3183v1",
  institution = "PeerJ Preprints",
  month       =  aug,
  year        =  2017,
  language    = "en"
}

@TECHREPORT{Ellis2017,
  title       = "How to share data for collaboration",
  author      = "Ellis, Shannon E and Leek, Jeffrey T",
  publisher   = "PeerJ Inc.",
  number      = "e3139v1",
  institution = "PeerJ Preprints",
  month       =  aug,
  year        =  2017,
  language    = "en"
}

@misc{EML-about,
	url = {https://knb.ecoinformatics.org/#external//emlparser/docs/index.html},
	urldate = {2018-12-18TZ}
}


@article{Wickham2014,
  doi = {10.18637/jss.v059.i10},
  url = {https://doi.org/10.18637/jss.v059.i10},
  year  = {2014},
  publisher = {Foundation for Open Access Statistic},
  volume = {59},
  number = {10},
  author = {Hadley Wickham},
  title = {Tidy Data},
  journal = {Journal of Statistical Software}
}


@ARTICLE{Piwowar2007,
  title     = "Sharing detailed research data is associated with increased
               citation rate",
  author    = "Piwowar, Heather A and Day, Roger S and Fridsma, Douglas B",
  journal   = "PloS one",
  publisher = "journals.plos.org",
  volume    =  2,
  number    =  3,
  pages     = "e308",
  month     =  mar,
  year      =  2007,
  language  = "en"
}

@ARTICLE{Rowhani-Farid2016,
  title    = "Has open data arrived at the British Medical Journal ({BMJ)}? An
              observational study",
  author   = "Rowhani-Farid, Anisa and Barnett, Adrian G",
  journal  = "BMJ open",
  volume   =  6,
  number   =  10,
  pages    = "e011784",
  month    =  oct,
  year     =  2016,
  language = "en"
}


@misc{plos-comp-bio-data, 
      title = {PLOS Computational Biology}, 
      url = {https://journals.plos.org/ploscompbiol/s/data-availability},
      journal = {PLOS ONE}, 
      publisher = {Public Library of Science}}


@ARTICLE{google-data-search,
  title    = "Google unveils search engine for open data",
  author   = "Castelvecchi, Davide",
  journal  = "Nature",
  volume   =  561,
  number   =  7722,
  pages    = "161--162",
  month    =  sep,
  year     =  2018,
  language = "en"
}

@misc{Maerz2014, 
      title={Stream salamander mark-recapture abundance study at the Coweeta Hydrologic Laboratory, Otto, NC.}, 
      url={https://portal.edirepository.org/nis/mapbrowse?packageid=knb-lter-cwt.3091.13},
      DOI={10.6073/PASTA/EBE25D39A2AA40E92B9091C42AE5C294}, 
      publisher={Environmental Data Initiative}, 
      author={Coweeta Long Term Ecological Research Program and Maerz, John}, 
      year={2014} 
      }

@misc{Schleunes2020,
	title = {Top spider biologist’s research under fire},
	url = {https://www.the-scientist.com/news-opinion/top-spider-biologists-research-under-fire-67083},
	abstract = {After the initial announcements of two retractions, scientists have mobilized to interrogate the data in nearly 150 of Jonathan Pruitt's papers.},
	language = {en},
	urldate = {2020-09-23},
	journal = {The Scientist},
	author = {Schleunes, Amy},
	month = feb,
	year = {2020}
}


@ARTICLE{Viglione2020,
  title    = "'Avalanche' of spider-paper retractions shakes
              behavioural-ecology community",
  author   = "Viglione, Giuliana",
  journal  = "Nature",
  volume   =  578,
  number   =  7794,
  pages    = "199--200",
  month    =  feb,
  year     =  2020,
  language = "en"
}
